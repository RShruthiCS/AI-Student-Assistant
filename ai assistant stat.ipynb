{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dcec26-a764-4b08-997c-0dcea15218fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f153aab7-05e2-4a81-ae19-c1b474b10d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Add all your chapters here\n",
    "pdf_files = [\"ISLPcpt1,2.pdf\", \"ISLPcpt3.pdf\", \"ISLPcpt4.pdf\", \"ISLPcpt5.pdf\", \"ISLPcpt5.pdf\"]\n",
    "\n",
    "documents_plumber = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                documents_plumber.append(\n",
    "                    Document(page_content=text, metadata={\"source\": pdf_path, \"page\": i+1})\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911e904c-5909-49a7-9765-3266ce868972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdfplumber: 253 pages total\n",
      "1\n",
      "Introduction\n",
      "An Overview of Statistical Learning\n",
      "Statisticallearningreferstoavastsetoftoolsforunderstandingdata.These\n",
      "tools can be classified as supervised or unsupervised. Broadly speaking,\n",
      "supervised statistical learning involves building a statistical model for pre-\n",
      "dicting, or estimating, an output based on one or more inputs. Problems of\n",
      "thisnatureoccurinfieldsasdiverseasbusiness,medicine,astrophysics,and\n",
      "public policy. With unsupervised statistical learning, there are inputs but\n",
      "no supervising output; nevertheless we can learn relationships and struc-\n",
      "ture from such data. To provide an illustration of some applications of\n",
      "statistical learning, we briefly discuss three real-world data sets that are\n",
      "considered in this book.\n",
      "Wage Data\n",
      "In this application (which we refer to as the Wage data set throughout this\n",
      "book), we examine a number of factors that relate to wages for a group of\n",
      "men from the Atlantic region of the United States. In particular, we wish\n",
      "tounderstandtheassociationbetweenanemployee’sageandeducation,as\n",
      "wellasthecalendaryear,onhis wage.Consider,forexample,theleft-hand\n",
      "panelofFigure1.1,whichdisplayswageversusageforeachoftheindividu-\n",
      "alsinthedataset.Thereisevidencethatwageincreaseswithagebutthen\n",
      "decreases again after approximately age 60. The blue line, which provides\n",
      "an estimate of the average wage for a given age, makes this trend clearer.\n",
      "Givenanemployee’sage,wecanusethiscurvetopredicthiswage.However,\n",
      "it is also clear from Figure 1.1 that there is a significant amount of vari-\n",
      "ability associated with this average value, and so age alone is unlikely to\n",
      "provide an accurate prediction of a particular man’s wage.\n",
      "© Springer Nature Switzerland AG 2023 1\n",
      "G. James et al., An Introduction to Statistical Learning, Springer Texts in Statistics,\n",
      "https://doi.org/10.1007/978-3-031-38747-0_1\n"
     ]
    }
   ],
   "source": [
    "print(\"pdfplumber:\", len(documents_plumber), \"pages total\")\n",
    "print(documents_plumber[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9d6bc2-0422-4726-b77c-c02c8b0dbfaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1604\n",
      "1\n",
      "Introduction\n",
      "An Overview of Statistical Learning\n",
      "Statisticallearningreferstoavastsetoftoolsforunderstandingdata.These\n",
      "tools can be classified as supervised or unsupervised. Broadly speaking,\n",
      "supervised statistical learning involves building a statistical model for pre-\n",
      "dicting, or estimating, an output based on one or more inputs. Problems of\n",
      "thisnatureoccurinfieldsasdiverseasbusiness,medicine,astrophysics,and\n",
      "public policy. With unsupervised statistical learning, there are inputs but\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents_plumber)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(chunks[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51f9839-0e0f-488a-9d7a-2ae1adc30fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.31.2)\n",
      "Requirement already satisfied: Pillow in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69f5883-67a0-4333-a68f-6a9836f295e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in chunk[0]: 108\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# Example: Look at token length for a chunk\n",
    "sample_text = chunks[0].page_content\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "print(f\"Tokens in chunk[0]: {len(tokens)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d7729a-5758-4bf8-848d-8b8d2ad610b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/x37973bs11z07f191fqh8smr0000gn/T/ipykernel_99663/1728591684.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3bb08-82a2-4480-a2ea-91c20001068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e3f67f3-e2e9-45d8-af37-7a6a80e06089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks embedded and stored in ChromaDB!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/x37973bs11z07f191fqh8smr0000gn/T/ipykernel_99663/3426439783.py:10: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()  # Saves the DB\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Save vector DB to a folder for reuse\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "vectorstore.persist()  # Saves the DB\n",
    "print(\"✅ Chunks embedded and stored in ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9374d2d4-6b2c-4fbd-9ef4-320a87851876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (0.3.26)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/f6/d5/4861816a95b2f6993f1360cfb605aacb015506ee2090433a71de9cca8477/langchain-0.3.27-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-community in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (0.3.26)\n",
      "Collecting langchain-community\n",
      "  Obtaining dependency information for langchain-community from https://files.pythonhosted.org/packages/c8/bc/f8c7dae8321d37ed39ac9d7896617c4203248240a4835b136e3724b3bb62/langchain_community-0.3.27-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.74)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<1.0.0,>=0.3.9 from https://files.pythonhosted.org/packages/e2/52/7638394b88bc15083fd2c3752a843784d9d2d110d68fed6437c8607fb749/langchain_text_splitters-0.3.9-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: anyio in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/shruthiraghavan/anaconda3/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.8\n",
      "    Uninstalling langchain-text-splitters-0.3.8:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.26\n",
      "    Uninstalling langchain-0.3.26:\n",
      "      Successfully uninstalled langchain-0.3.26\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.26\n",
      "    Uninstalling langchain-community-0.3.26:\n",
      "      Successfully uninstalled langchain-community-0.3.26\n",
      "Successfully installed langchain-0.3.27 langchain-community-0.3.27 langchain-text-splitters-0.3.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ed21f4-c817-4081-b4e5-2ad5ec7a003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer:  In machine learning, supervised learning and unsupervised learning are two main categories of approaches.\n",
      "\n",
      "1. Supervised Learning: In this type of learning, the algorithm learns from labeled data, which means that each example in the dataset has a known output or label. The goal is to learn a mapping function between the input (predictor measurements) and output (response). Examples include regression and classification problems.\n",
      "\n",
      "2. Unsupervised Learning: In contrast, unsupervised learning deals with unlabeled data, where there are no predefined labels or outputs. The algorithm tries to find patterns, structures, or relationships within the data on its own. Clustering and dimensionality reduction are common examples of unsupervised learning techniques.\n",
      "\n",
      "The context you provided discusses a scenario where an analysis might not be clearly supervised or unsupervised. This happens when we have more observations (n) than predictor measurements (m<n), and both predictor measurements and a response variable are available. In such cases, the problem can be approached from either a supervised learning perspective (using the response as the target variable) or an unsupervised learning perspective (ignoring the response and focusing on finding patterns in the data).\n",
      "\n",
      " Sources:\n",
      "- ? page 24\n",
      "- ISLPcpt1,2.pdf page 25\n",
      "- ISLPcpt1,2.pdf page 25\n",
      "- ISLPcpt1,2.pdf page 25\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\", temperature=0)  # or llama3, gemma, etc.\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"What is the difference between supervised and unsupervised learning?\"\n",
    "response = qa_chain(query)\n",
    "\n",
    "print(\" Answer:\", response[\"result\"])\n",
    "print(\"\\n Sources:\")\n",
    "for d in response[\"source_documents\"]:\n",
    "    print(f\"- {d.metadata.get('source','?')} page {d.metadata.get('page','?')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aab1b7c-97e8-46fe-b562-dbd80aa69444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
